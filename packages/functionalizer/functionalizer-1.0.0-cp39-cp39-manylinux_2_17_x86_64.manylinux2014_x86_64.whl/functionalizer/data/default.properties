# Previous 40g let to failures like
# "Missing an output location for shuffle X"
# Sleuthing seems to indicate this happens when the executor runs low on
# memory...
spark.executor.cores=10
spark.executor.memory=30g
spark.executor.extraJavaOptions="-Dio.netty.tryReflectionSetAccessible=true"

spark.driver.memory=60g
spark.driver.maxResultSize=20g
spark.driver.extraJavaOptions="-Dio.netty.tryReflectionSetAccessible=true"

# recommended, not the default due to backwards compatibility
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max=512m

# default network and heartbeat timeouts
# see https://spark.apache.org/docs/2.3.0/configuration.html
spark.network.timeout=120s
spark.executor.heartbeatInterval=10s

spark.eventLog.enabled=true

spark.shuffle.compress=true
spark.checkpoints.compress=true

spark.sql.adaptive.coalescePartitions.minPartitionSize=134217728
spark.sql.autoBroadcastJoinThreshold=0
spark.sql.broadcastTimeout=600
spark.sql.catalogImplementation=hive
spark.sql.files.maxPartitionBytes=268435456
# ^^ 256 MB
spark.sql.hive.filesourcePartitionFileCacheSize=268435456
# ^^ 256 MB
spark.sql.sources.bucketing.maxBuckets=1000000
