{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathology Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixmil.paths import DATA\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from mixmil import MixMIL\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to apply MixMIL to the Camelyon dataset for the classification of histopathological slides as containing tumor or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(el, device):\n",
    "    \"\"\"\n",
    "    Move a nested structure of elements (dict, list, tuple, torch.Tensor, torch.nn.Module) to the specified device.\n",
    "\n",
    "    Parameters:\n",
    "    - el: Element or nested structure of elements to be moved to the device.\n",
    "    - device (torch.device): The target device, such as 'cuda' for GPU or 'cpu' for CPU.\n",
    "\n",
    "    Returns:\n",
    "    - Transferred element(s) in the same structure: Elements moved to the specified device.\n",
    "    \"\"\"\n",
    "    if isinstance(el, dict):\n",
    "        return {k: to_device(v, device) for k, v in el.items()}\n",
    "    elif isinstance(el, (list, tuple)):\n",
    "        return [to_device(x, device) for x in el]\n",
    "    elif isinstance(el, (torch.Tensor, torch.nn.Module)):\n",
    "        return el.to(device)\n",
    "    else:\n",
    "        return el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from reading the Camelyon dataset. The bag features are stored in multiple `.csv` files. The association of the files, their labels and whether they are train or test samples is stored in the `Camelyon16.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-tumor/test_033.csv</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/normal_148.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/test_095.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/normal_025.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/test_087.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/normal_006.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-tumor/tumor_003.csv</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/normal_018.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-tumor/tumor_017.csv</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/test_067.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  split\n",
       "file                                 \n",
       "1-tumor/test_033.csv         1   test\n",
       "0-normal/normal_148.csv      0  train\n",
       "0-normal/test_095.csv        0   test\n",
       "0-normal/normal_025.csv      0  train\n",
       "0-normal/test_087.csv        0   test\n",
       "...                        ...    ...\n",
       "0-normal/normal_006.csv      0  train\n",
       "1-tumor/tumor_003.csv        1  train\n",
       "0-normal/normal_018.csv      0  train\n",
       "1-tumor/tumor_017.csv        1  train\n",
       "0-normal/test_067.csv        0   test\n",
       "\n",
       "[399 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_index_file = DATA / \"camelyon16\" / \"Camelyon16.csv\"\n",
    "bagdf = pd.read_csv(dataset_index_file)\n",
    "bagdf.columns = [\"file\", \"label\"]\n",
    "bagdf[\"file\"] = bagdf[\"file\"].str.replace(\"datasets/Camelyon16/\", \"\")\n",
    "bagdf[\"split\"] = bagdf[\"file\"].apply(lambda x: \"test\" if \"test\" in x else \"train\")\n",
    "bagdf = bagdf.set_index(\"file\")\n",
    "bagdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and save `anndata` files containing train and test sets collected from the true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [01:58<00:00,  2.27it/s]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.18it/s]\n",
      "/home/icb/alessandro.palma/miniconda3/envs/sslbio-env/lib/python3.9/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "dtype = \"float32\"\n",
    "\n",
    "if not (DATA / \"camelyon16\" / \"full_test.h5ad\").exists() or not (DATA / \"full_camelyon16\" / \"full_train.h5ad\").exists():\n",
    "    train_data = []\n",
    "    train_bag_indices = []\n",
    "    for _, row in tqdm(list(bagdf[bagdf[\"split\"] == \"train\"].iterrows())):\n",
    "        train_data.append(pd.read_csv(dataset_index_file.parent / row.name).values.astype(dtype))\n",
    "        train_bag_indices.extend([row.name] * len(train_data[-1]))\n",
    "\n",
    "    test_data = []\n",
    "    test_bag_indices = []\n",
    "    for _, row in tqdm(list(bagdf[bagdf[\"split\"] == \"test\"].iterrows())):\n",
    "        test_data.append(pd.read_csv(dataset_index_file.parent / row.name).values.astype(dtype))\n",
    "        test_bag_indices.extend([row.name] * len(test_data[-1]))\n",
    "\n",
    "    i_train = np.array([idx for idx, x in enumerate(train_data) for _ in range(len(x))])\n",
    "    X_train = np.concatenate(train_data, 0).astype(dtype)\n",
    "    X_test = np.concatenate(test_data, 0).astype(dtype)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    train_obs = pd.DataFrame(\n",
    "        {\"bag\": train_bag_indices, \"label\": bagdf.loc[train_bag_indices][\"label\"].values, \"split\": \"train\"}\n",
    "    )\n",
    "    train_adata = ad.AnnData(X_train, obs=train_obs)\n",
    "    test_obs = pd.DataFrame(\n",
    "        {\"bag\": test_bag_indices, \"label\": bagdf.loc[test_bag_indices][\"label\"].values, \"split\": \"test\"}\n",
    "    )\n",
    "    test_adata = ad.AnnData(X_test, obs=test_obs)\n",
    "\n",
    "    test_adata.write(DATA / \"camelyon16\" / \"full_test.h5ad\")\n",
    "    train_adata.write(DATA / \"camelyon16\" / \"full_train.h5ad\")\n",
    "else:\n",
    "    print(\"Loading precomputed anndatas\")\n",
    "    train_adata = ad.read_h5ad(DATA / \"camelyon16\" / \"full_train.h5ad\")\n",
    "    test_adata = ad.read_h5ad(DATA / \"camelyon16\" / \"full_test.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize bags of observations as tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train data\n",
    "train_bags = train_adata.obs[\"bag\"].unique().tolist()\n",
    "Xs = [torch.Tensor(train_adata[train_adata.obs[\"bag\"] == bag].X) for bag in train_bags]\n",
    "F = torch.ones((len(train_bags), 1))\n",
    "Y = torch.Tensor(train_adata.obs[[\"bag\", \"label\"]].drop_duplicates().set_index(\"bag\").loc[train_bags].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data, following official train-test split\n",
    "test_bags = test_adata.obs[\"bag\"].unique().tolist()\n",
    "test_Xs = [torch.Tensor(test_adata[test_adata.obs[\"bag\"] == bag].X) for bag in test_bags]\n",
    "test_Y = torch.Tensor(test_adata.obs[[\"bag\", \"label\"]].drop_duplicates().set_index(\"bag\").loc[test_bags].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we initialize MixMIL with a simple GLMM and use it for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GLMM Init: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.698 Spearman: 0.333\n"
     ]
    }
   ],
   "source": [
    "# initialize model with mean model and Bernoulli likelihood\n",
    "model = MixMIL.init_with_mean_model(Xs, F, Y, likelihood=\"binomial\", n_trials=1)\n",
    "y_pred_mean = model.predict(test_Xs)\n",
    "print(\n",
    "    \"Test AUC:\",\n",
    "    round(roc_auc_score(test_Y, y_pred_mean), 3),\n",
    "    \"Spearman:\",\n",
    "    round(st.spearmanr(test_Y, y_pred_mean).correlation, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train MixMIL starting from the GLMM initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.977 Spearman: 0.802\n"
     ]
    }
   ],
   "source": [
    "# train model for 1000 epochs\n",
    "device = \"cuda:0\"\n",
    "model, Xs, F, Y, test_Xs, test_Y = to_device((model, Xs, F, Y, test_Xs, test_Y), device)\n",
    "model.train(Xs, F, Y, n_epochs=1000)\n",
    "model.to(\"cpu\")\n",
    "test_Xs = [x.cpu() for x in test_Xs]\n",
    "y_pred = model.predict(test_Xs).cpu().numpy()\n",
    "y_true = test_Y.cpu().numpy()\n",
    "print(\n",
    "    \"Test AUC:\",\n",
    "    round(roc_auc_score(y_true, y_pred), 3),\n",
    "    \"Spearman:\",\n",
    "    round(st.spearmanr(y_true, y_pred).correlation, 3),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
