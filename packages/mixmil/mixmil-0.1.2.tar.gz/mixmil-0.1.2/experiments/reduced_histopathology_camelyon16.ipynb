{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathology Experiment (Reduced Dimension)\n",
    "> In this version we run PCA to half the data dimensionality to enable in-memory training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixmil.paths import DATA\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from mixmil import MixMIL\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(el, device):\n",
    "    \"\"\"\n",
    "    Move a nested structure of elements (dict, list, tuple, torch.Tensor, torch.nn.Module) to the specified device.\n",
    "\n",
    "    Parameters:\n",
    "    - el: Element or nested structure of elements to be moved to the device.\n",
    "    - device (torch.device): The target device, such as 'cuda' for GPU or 'cpu' for CPU.\n",
    "\n",
    "    Returns:\n",
    "    - Transferred element(s) in the same structure: Elements moved to the specified device.\n",
    "    \"\"\"\n",
    "    if isinstance(el, dict):\n",
    "        return {k: to_device(v, device) for k, v in el.items()}\n",
    "    elif isinstance(el, (list, tuple)):\n",
    "        return [to_device(x, device) for x in el]\n",
    "    elif isinstance(el, (torch.Tensor, torch.nn.Module)):\n",
    "        return el.to(device)\n",
    "    else:\n",
    "        return el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from reading the Camelyon dataset. The bag features are stored in multiple `.csv` files. The association of the files, their labels and whether they are train or test samples are stored in the `Camelyon16.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-tumor/test_033.csv</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/normal_148.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/test_095.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/normal_025.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/test_087.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/normal_006.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-tumor/tumor_003.csv</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/normal_018.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-tumor/tumor_017.csv</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-normal/test_067.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  split\n",
       "file                                 \n",
       "1-tumor/test_033.csv         1   test\n",
       "0-normal/normal_148.csv      0  train\n",
       "0-normal/test_095.csv        0   test\n",
       "0-normal/normal_025.csv      0  train\n",
       "0-normal/test_087.csv        0   test\n",
       "...                        ...    ...\n",
       "0-normal/normal_006.csv      0  train\n",
       "1-tumor/tumor_003.csv        1  train\n",
       "0-normal/normal_018.csv      0  train\n",
       "1-tumor/tumor_017.csv        1  train\n",
       "0-normal/test_067.csv        0   test\n",
       "\n",
       "[399 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_index_file = DATA / \"camelyon16\" / \"Camelyon16.csv\"\n",
    "bagdf = pd.read_csv(dataset_index_file)\n",
    "bagdf.columns = [\"file\", \"label\"]\n",
    "bagdf[\"file\"] = bagdf[\"file\"].str.replace(\"datasets/Camelyon16/\", \"\")\n",
    "bagdf[\"split\"] = bagdf[\"file\"].apply(lambda x: \"test\" if \"test\" in x else \"train\")\n",
    "bagdf = bagdf.set_index(\"file\")\n",
    "bagdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and save anndata files containing train and test sets collected from the true. We collect and apply the model to 128 PCA features, scaled using the training set statistics and saved in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed anndatas\n"
     ]
    }
   ],
   "source": [
    "dtype = \"float32\"\n",
    "n_pcs = 128\n",
    "\n",
    "if not (DATA / \"camelyon16\" / \"test.h5ad\").exists() or not (DATA / \"camelyon16\" / \"train.h5ad\").exists():\n",
    "    train_data = []\n",
    "    train_bag_indices = []\n",
    "    for _, row in tqdm(list(bagdf[bagdf[\"split\"] == \"train\"].iterrows())):\n",
    "        train_data.append(pd.read_csv(dataset_index_file.parent / row.name).values.astype(dtype))\n",
    "        train_bag_indices.extend([row.name] * len(train_data[-1]))\n",
    "\n",
    "    test_data = []\n",
    "    test_bag_indices = []\n",
    "    for _, row in tqdm(list(bagdf[bagdf[\"split\"] == \"test\"].iterrows())):\n",
    "        test_data.append(pd.read_csv(dataset_index_file.parent / row.name).values.astype(dtype))\n",
    "        test_bag_indices.extend([row.name] * len(test_data[-1]))\n",
    "\n",
    "    i_train = np.array([idx for idx, x in enumerate(train_data) for _ in range(len(x))])\n",
    "    X_train = np.concatenate(train_data, 0).astype(dtype)\n",
    "    X_test = np.concatenate(test_data, 0).astype(dtype)\n",
    "    pca = PCA(n_components=n_pcs)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(pca.fit_transform(X_train))\n",
    "    X_test = scaler.transform(pca.transform(X_test))\n",
    "\n",
    "    train_obs = pd.DataFrame(\n",
    "        {\"bag\": train_bag_indices, \"label\": bagdf.loc[train_bag_indices][\"label\"].values, \"split\": \"train\"}\n",
    "    )\n",
    "    train_adata = ad.AnnData(X_train, obs=train_obs, var=pd.DataFrame(index=[f\"PC{i}\" for i in range(n_pcs)]))\n",
    "    test_obs = pd.DataFrame(\n",
    "        {\"bag\": test_bag_indices, \"label\": bagdf.loc[test_bag_indices][\"label\"].values, \"split\": \"test\"}\n",
    "    )\n",
    "    test_adata = ad.AnnData(X_test, obs=test_obs, var=pd.DataFrame(index=[f\"PC{i}\" for i in range(n_pcs)]))\n",
    "\n",
    "    test_adata.write(DATA / \"camelyon16\" / \"test.h5ad\")\n",
    "    train_adata.write(DATA / \"camelyon16\" / \"train.h5ad\")\n",
    "else:\n",
    "    print(\"Loading precomputed anndatas\")\n",
    "    train_adata = ad.read_h5ad(DATA / \"camelyon16\" / \"train.h5ad\")\n",
    "    test_adata = ad.read_h5ad(DATA / \"camelyon16\" / \"test.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train data\n",
    "train_bags = train_adata.obs[\"bag\"].unique().tolist()\n",
    "Xs = [torch.Tensor(train_adata[train_adata.obs[\"bag\"] == bag].X) for bag in train_bags]\n",
    "F = torch.ones((len(train_bags), 1))\n",
    "Y = torch.Tensor(train_adata.obs[[\"bag\", \"label\"]].drop_duplicates().set_index(\"bag\").loc[train_bags].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data, following official train-test split\n",
    "test_bags = test_adata.obs[\"bag\"].unique().tolist()\n",
    "test_Xs = [torch.Tensor(test_adata[test_adata.obs[\"bag\"] == bag].X) for bag in test_bags]\n",
    "test_Y = torch.Tensor(test_adata.obs[[\"bag\", \"label\"]].drop_duplicates().set_index(\"bag\").loc[test_bags].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize MixMIL with a simple GLMM and use it for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66eb150f90564e659021f5bcb6cafdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GLMM Init:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.706 Spearman: 0.346\n"
     ]
    }
   ],
   "source": [
    "# initialize model with mean model and Bernoulli likelihood\n",
    "model = MixMIL.init_with_mean_model(Xs, F, Y, likelihood=\"binomial\", n_trials=1)\n",
    "y_pred_mean = model.predict(test_Xs)\n",
    "print(\n",
    "    \"Test AUC:\",\n",
    "    round(roc_auc_score(test_Y, y_pred_mean), 3),\n",
    "    \"Spearman:\",\n",
    "    round(st.spearmanr(test_Y, y_pred_mean).correlation, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train MixMIL starting from the GLMM initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1620a6afc2d94f0e9202c7cebd220877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.969 Spearman: 0.789\n"
     ]
    }
   ],
   "source": [
    "# train model for 1000 epochs\n",
    "device = \"cuda:0\"\n",
    "model, Xs, F, Y, test_Xs, test_Y = to_device((model, Xs, F, Y, test_Xs, test_Y), device)\n",
    "model.train(Xs, F, Y, n_epochs=1000)\n",
    "y_pred = model.predict(test_Xs).cpu().numpy()\n",
    "y_true = test_Y.cpu().numpy()\n",
    "print(\n",
    "    \"Test AUC:\",\n",
    "    round(roc_auc_score(y_true, y_pred), 3),\n",
    "    \"Spearman:\",\n",
    "    round(st.spearmanr(y_true, y_pred).correlation, 3),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
