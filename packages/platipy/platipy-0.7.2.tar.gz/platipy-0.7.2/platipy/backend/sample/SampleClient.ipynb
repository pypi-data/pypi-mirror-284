{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Client Notebook\n",
    "\n",
    "This Notebook demonstrates how to interact with the running service using http requests. The sample app provides a very primitive body segmentation algorithm which this Notebook will run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Before running this Notebook, follow these steps from your command line to get the sample service up and running:\n",
    "\n",
    "1. Make sure Python libraries required are up-to-date:\n",
    "\n",
    "```\n",
    "pip install -r <PLATIPY_PATH>/requirements.txt\n",
    "```\n",
    "\n",
    "2. Change into the directory containing the sample app\n",
    "\n",
    "```\n",
    "cd <PLATIPY_PATH>/framework/sample\n",
    "```\n",
    "\n",
    "3. Initialize the database for the framework\n",
    "\n",
    "```\n",
    "python -m platipy.backend.manage initdb \n",
    "```\n",
    "\n",
    "4. Add an API key for this client\n",
    "\n",
    "```\n",
    "python -m platipy.backend.manage key -a sample_client\n",
    "```\n",
    "\n",
    "Copy and paste the key output from the last command and copy into the api_key variable in the next cell!\n",
    "\n",
    "5. Run the service\n",
    "\n",
    "```\n",
    "python sample.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required for this notebook\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pydicom\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../../../\") # Path containing PlatiPy library\n",
    "from PLATIPY_PATH.dicom.communication import DicomConnector\n",
    "\n",
    "# API Key generated for this client (see above description)\n",
    "api_key = 'YOUR-API-KEY'\n",
    "\n",
    "# URL at which the service is running\n",
    "base_url = 'http://localhost:8000'\n",
    "\n",
    "# The name of the algorithm running in the service\n",
    "algorithm_name = 'Primitive Body Segmentation'\n",
    "\n",
    "# These are the API endpoints which the client will use to communicate with the service\n",
    "api_dicom_location = '{0}/api/dicomlocation'.format(base_url)\n",
    "api_dataset = '{0}/api/dataset'.format(base_url)\n",
    "api_dataset_ready = '{0}/api/dataset/ready'.format(base_url)\n",
    "api_data_object = '{0}/api/dataobject'.format(base_url)\n",
    "api_trigger = '{0}/api/trigger'.format(base_url)\n",
    "api_algorithm = '{0}/api/algorithm'.format(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's test that the service is up and running and that we can authenticate\n",
    "\n",
    "We'll fetch the list of available algorithms from the service to achieve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the algorithm and the default settings\n",
    "algorithm = None\n",
    "r = requests.get(api_algorithm, headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    for a in r.json():\n",
    "        pprint(a)\n",
    "        if a['name'] == algorithm_name:\n",
    "            algorithm = a\n",
    "    print(\"\")\n",
    "    print(\"Look's Good!\")\n",
    "else:\n",
    "    print(\"Oops, something went wrong. Ensure the service is running at the base_url configured and that the API Key has been generated and set in api_key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset\n",
    "\n",
    "Next, we create a Dataset on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Dataset\n",
    "dataset = None\n",
    "r = requests.post(api_dataset, headers={'API_KEY': api_key}, data={})\n",
    "if r.status_code >= 200:\n",
    "        dataset = r.json()\n",
    "        \n",
    "pprint(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Data Objects to the Dataset\n",
    "\n",
    "Now that we have the Dataset, we want to add some data objects to it. In the case of this segmentation algorithm, all we need to add is one Dicom object (CT image series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Dicom file to the dataset\n",
    "path_to_ct = '../../dicom/data/phantom/CT'\n",
    "\n",
    "# Get the Series UID of this Data Object\n",
    "series_instance_UID = None\n",
    "for f in os.listdir(path_to_ct):\n",
    "    \n",
    "    try:\n",
    "        d = pydicom.read_file(os.path.join(path_to_ct, f))\n",
    "        series_instance_UID = d.SeriesInstanceUID\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "data = {'dataset': dataset['id'],\n",
    "        'type': 'DICOM',\n",
    "        'dicom_retrieve': 'SEND',\n",
    "        'seriesUID': '2.16.840.1.114362.1.6.6.7.16915.10833836991.445328177.1068.305'}\n",
    "data_object = None\n",
    "r = requests.post(api_data_object, headers={'API_KEY': api_key}, data=data)\n",
    "if r.status_code >= 200:\n",
    "        data_object = r.json()\n",
    "        \n",
    "pprint(data_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the Dicom Data to the Server\n",
    "\n",
    "Now that the Data Object for the image series has been created on the server, we can send it the Dicom Data itself.\n",
    "\n",
    "Since we set the Data Object's dicom_retrieve property to SEND, the server expects us to SEND the data object to it. If we set MOVE or GET, the Server will attempt to retrieve the Dicom object from the Dicom location configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and verify the Dicom Endpoint\n",
    "dicom_connector = DicomConnector(host='127.0.0.1', port=7777)\n",
    "dicom_connector.verify()\n",
    "\n",
    "# Send the image series to the Dicom Location\n",
    "img_series = [os.path.join(path_to_ct, f) for f in os.listdir(path_to_ct)]\n",
    "dicom_connector.send_dcm(img_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we want to send the data objects as Nifti instead of Dicom...\n",
    "\n",
    "The following cell demonstrates how to send the data as a Nifti object, bypassing the need for Dicom communication. Note the following is a sample and should only be run if the data 'type' above is set to 'FILE' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "load_path = sitk.ImageSeriesReader().GetGDCMSeriesFileNames(path_to_ct)\n",
    "img = sitk.ReadImage(load_path)\n",
    "\n",
    "path_to_nii = f'testcase.nii.gz'\n",
    "\n",
    "sitk.WriteImage(img, path_to_nii)\n",
    "\n",
    "data_object = None\n",
    "\n",
    "# Get the Series UID of this Data Object\n",
    "with open(path_to_nii,'rb') as file:\n",
    "\n",
    "    data = {'dataset': dataset['id'],\n",
    "            'type': 'FILE',\n",
    "            'file_name': 'case_test.nii.gz'}\n",
    "    \n",
    "    r = requests.post(api_data_object, headers={'API_KEY': api_key}, data=data, files={'file_data':file})\n",
    "    if r.status_code >= 200:\n",
    "            data_object = r.json()\n",
    "        \n",
    "pprint(data_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresh Data Object\n",
    "\n",
    "Now we can refresh our Data Object from the Server, to see if it has been fetched yet or not. The is_fetched property tells us if it has been fetched or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('{0}/{1}'.format(api_data_object, data_object['id']), headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    data_object = r.json()\n",
    "    \n",
    "if data_object['is_fetched']:\n",
    "    print('The server has the Dicom data and is ready!')\n",
    "else:\n",
    "    print('The server is still receiving the Dicom data or something has gone wrong.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if Dataset ready\n",
    "\n",
    "Our dataset only has one object, but when you have multiple objects it can be useful to determine if the dataset is ready to run the algorithm on. So, determine if all objects within the dataset have been fetched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('{0}/{1}'.format(api_dataset_ready, dataset['id']), headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    if r.json()['ready']:\n",
    "        print(\"The Dataset is ready, let's run the algorithm!\")\n",
    "    else:\n",
    "        print(\"Nope, the dataset isn't ready yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm configuration\n",
    "\n",
    "One last thing we want to do before we run our algorithm is configure the settings. In the next cell, we first print out the default settings, then make some modifications to it to use for our run of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Default Settings:')\n",
    "pprint(algorithm['default_settings'])\n",
    "\n",
    "settings = algorithm['default_settings']\n",
    "settings['seed'] = [5,5,5]\n",
    "settings['lowerThreshold'] = -1024\n",
    "settings['upperThreshold'] = -750\n",
    "settings['vectorRadius'] = [10, 10, 10]\n",
    "\n",
    "print()\n",
    "print('Custom Settings:')\n",
    "pprint(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the algorithm!\n",
    "\n",
    "Now it's time to run our algorithm. We pass the dataset we want to run the algorithm on, the name of the algorithm and our custom settings.\n",
    "\n",
    "Once triggered, we are given a URL to poll for the progress of the algorithm. Using this we can determine when the algorithm has finished running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the algorithm with our dataset containing the data object\n",
    "data={'dataset': dataset['id'],\n",
    "     'algorithm': algorithm['name'],\n",
    "     'config': json.dumps(settings)}\n",
    "r = requests.post(api_trigger, headers={'API_KEY': api_key}, data=data)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    # Poll the URL given to determine the progress of the task\n",
    "    poll_url = '{0}{1}'.format(base_url, r.json()['poll'])\n",
    "    \n",
    "    while(1):\n",
    "        r = requests.get(poll_url, headers={'API_KEY': api_key})\n",
    "        status = r.json()\n",
    "        print(status)\n",
    "\n",
    "        if status['state'] == 'SUCCESS' or status['state'] == 'FAILURE':\n",
    "            break\n",
    "\n",
    "        time.sleep(2)\n",
    "else:\n",
    "    print(r.json())\n",
    "    \n",
    "print('Algorithm Processing Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the output\n",
    "\n",
    "Once the algorithm finishes, we can update the dataset from the server to see what output objects we have. For those objects we are interested in, we download from the server!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the latest dataset to see the output objects and download the Nifti file!\n",
    "r = requests.get('{0}/{1}'.format(api_dataset, dataset['id']), headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    dataset = r.json()\n",
    "    pprint(dataset)\n",
    "\n",
    "    for d in dataset['output_data_objects']:\n",
    "        if d['path'].endswith('nii.gz'):\n",
    "            #print(d)\n",
    "            r = requests.get('http://localhost:8000/api/dataobject/download/{0}'.format(d['id']), headers={'API_KEY': api_key})\n",
    "            filename = r.headers['Content-Disposition'].split('filename=')[1]\n",
    "            print('Downloading to: {0}'.format(filename))\n",
    "            open(filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it\n",
    "\n",
    "This Notebook demonstrated the basics of running a simple segmentation algorithm on a CT image series, and downloading the resulting Nifti mask.\n",
    "\n",
    "There is more complex stuff we can do that this. We can give the algorithm Nifti files as input, or have it automatically fetch the Dicom itself. We can also have the algorithm send generated Dicom objects (in this case RTStruct files) to a Dicom Location of our choice. Documentation and examples on how to achieve this will follow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
