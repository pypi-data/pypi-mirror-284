{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import the Zenbase Library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install {package}: {e}\")\n",
    "        raise\n",
    "\n",
    "def install_packages(packages):\n",
    "    for package in packages:\n",
    "        install_package(package)\n",
    "\n",
    "try:\n",
    "    # Check if running in Google Colab\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install the zenbase package if running in Google Colab\n",
    "    # install_package('zenbase')\n",
    "    # Install the zenbse package from a GitHub branch if running in Google Colab\n",
    "    install_package('git+https://github.com/zenbase-ai/lib.git@main#egg=zenbase&subdirectory=py')\n",
    "\n",
    "    # List of other packages to install in Google Colab\n",
    "    additional_packages = [\n",
    "        'python-dotenv',\n",
    "        'arize-phoenix[evals]',\n",
    "        'openai',\n",
    "        'langchain',\n",
    "        'langchain_openai'\n",
    "    ]\n",
    "    \n",
    "    # Install additional packages\n",
    "    install_packages(additional_packages)\n",
    "\n",
    "# Now import the zenbase library\n",
    "try:\n",
    "    import zenbase\n",
    "except ImportError as e:\n",
    "    print(\"Failed to import zenbase: \", e)\n",
    "    raise"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure the Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "\n",
    "load_dotenv(Path(\"../../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# initiate the phoenix app\n",
    "import phoenix as px\n",
    "px.launch_app()\n",
    "# initiate the phoenix client\n",
    "arize_phoenix = px.Client()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from zenbase.utils import ksuid\n",
    "from zenbase.adaptors.arize import ZenArizeAdaptor\n",
    "# setup datasets\n",
    "import datasets\n",
    "gsm8k_dataset = datasets.load_dataset(\"gsm8k\", \"main\")\n",
    "zen_arize_adaptor = ZenArizeAdaptor(arize_phoenix)\n",
    "TESTSET_SIZE = 2\n",
    "TRAINSET_SIZE = 5\n",
    "VALIDATIONSET_SIZE = 2\n",
    "\n",
    "\n",
    "def create_dataset_with_examples(zen_arize_adaptor: ZenArizeAdaptor, prefix: str, item_set: list) -> str:\n",
    "    dataset_name = ksuid(prefix=prefix)\n",
    "\n",
    "    inputs = [{\"question\": example[\"question\"]} for example in item_set]\n",
    "    expected_outputs = [{\"answer\": example[\"answer\"]} for example in item_set]\n",
    "    zen_arize_adaptor.add_examples_to_dataset(dataset_name, inputs, expected_outputs)\n",
    "    return dataset_name\n",
    "\n",
    "train_set = create_dataset_with_examples(\n",
    "        zen_arize_adaptor,\n",
    "        \"GSM8K_train_set\",\n",
    "        list(gsm8k_dataset[\"train\"].select(range(TRAINSET_SIZE))),\n",
    "    )\n",
    "\n",
    "validation_set = create_dataset_with_examples(\n",
    "        zen_arize_adaptor,\n",
    "        \"GSM8K_validation_set\",\n",
    "        list(gsm8k_dataset[\"train\"].select(range(TRAINSET_SIZE + 1, TRAINSET_SIZE + VALIDATIONSET_SIZE + 1))),\n",
    "    )\n",
    "\n",
    "test_set = create_dataset_with_examples(\n",
    "        zen_arize_adaptor,\n",
    "        \"GSM8K_test_set\",\n",
    "        list(gsm8k_dataset[\"test\"].select(range(TESTSET_SIZE))),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What you already have should look like below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your OpenAI Call should look like this with LangChain (It could be with OpenAI too, doesn't matter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_chain(inputs) -> str:\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples.\",  # noqa\n",
    "        )\n",
    "    ]\n",
    "    messages.append((\"user\", \"{question}\"))\n",
    "\n",
    "    chain = ChatPromptTemplate.from_messages(messages) | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "\n",
    "    print(\"Mathing...\")\n",
    "    answer = chain.invoke(inputs[\"inputs\"])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your Scoring Function should look like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def score_answer(output: str, expected: dict):\n",
    "    print(output, expected[\"outputs\"])\n",
    "    \"\"\"The first argument is the return value from the `langchain_chain` function above.\"\"\"\n",
    "    score = int(output == expected[\"outputs\"][\"answer\"].split(\"#### \")[-1])\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your Evaluation should look like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.experiments import run_experiment\n",
    "\n",
    "experiment = run_experiment(\n",
    "                arize_phoenix.get_dataset(name=test_set),\n",
    "                langchain_chain,\n",
    "                experiment_name=\"Experiment-Name\",\n",
    "                evaluators=[score_answer],\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How you should do the few-shot learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rewrite your langchain_chain function to use the `zenbase` decorators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from zenbase.core.managers import ZenbaseTracer\n",
    "\n",
    "zenbase_tracer = ZenbaseTracer()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenbase.types import LMRequest, LMDemo\n",
    "@zenbase_tracer\n",
    "def zen_chain(request: LMRequest) -> str:\n",
    "    print(request)\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples.\",  # noqa\n",
    "        )\n",
    "    ]\n",
    "    for demo in request.zenbase.task_demos:\n",
    "        messages += [\n",
    "            (\"user\", demo.inputs[\"question\"]),\n",
    "            (\"assistant\", demo.outputs[\"answer\"]),\n",
    "        ]\n",
    "\n",
    "    messages.append((\"user\", \"{question}\"))\n",
    "\n",
    "    chain = ChatPromptTemplate.from_messages(messages) | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "\n",
    "    print(\"Mathing...\")\n",
    "    answer = chain.invoke(request.inputs[\"inputs\"])\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "return_langchain = zen_chain({\"inputs\": {\"question\": \"What is 2 + 2?\"}})\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make your evaluation function to use the langfuse from the LMDemo and the langfuse from the Zenbase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def score_answer(output: str, expected: dict):\n",
    "    print(output, expected[\"outputs\"])\n",
    "    \"\"\"The first argument is the return value from the `langchain_chain` function above.\"\"\"\n",
    "    # if there is any #### in the output\n",
    "    if \"####\" in expected[\"outputs\"][\"answer\"]:\n",
    "        output = output.split(\"#### \")[-1]\n",
    "\n",
    "    score = int(output == expected[\"outputs\"][\"answer\"].split(\"#### \")[-1])\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimize the few-shot learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define your optimizer:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenbase.optim.metric.labeled_few_shot import LabeledFewShot\n",
    "\n",
    "optimizer = LabeledFewShot(\n",
    "    demoset=zen_arize_adaptor.fetch_dataset_demos(train_set), ## The dataset to use for the few-shot learning and training\n",
    "    shots=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform the optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_fn, candidate_results, _ = optimizer.perform(\n",
    "    zen_chain,\n",
    "    evaluator=zen_arize_adaptor.metric_evaluator(\n",
    "        dataset=arize_phoenix.get_dataset(name=test_set), evaluators=[score_answer]\n",
    "    ),\n",
    "    samples=4,\n",
    "    concurrency=1,\n",
    "    rounds=1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the best function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = best_fn({\"inputs\":{\"question\": \"What is 2+2?\"}})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the best function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also save the zenbase params for re-use\n",
    "import pickle\n",
    "\n",
    "pickled_zenbase = pickle.dumps(best_fn.zenbase)\n",
    "zen_chain.zenbase = pickle.loads(pickled_zenbase)\n",
    "\n",
    "zen_chain({\"inputs\":{\"question\": \"What is 2+2?\"}}) # uses the best few-shot demos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
