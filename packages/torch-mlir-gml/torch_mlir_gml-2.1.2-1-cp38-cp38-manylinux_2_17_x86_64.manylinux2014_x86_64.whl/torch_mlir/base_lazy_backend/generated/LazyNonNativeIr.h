#pragma once

#include <torch/csrc/lazy/core/ir.h>
#include <torch/csrc/lazy/core/ir_builder.h>
#include <torch/csrc/lazy/core/internal_ops/ltc_ops.h>
#include <torch/csrc/lazy/core/shape_inference.h>
#include </main_checkout/torch-mlir/python/torch_mlir/csrc/base_lazy_backend/mlir_node.h>

// This file contains autogenerated LazyTensor Non Native IR nodes

namespace torch {
namespace lazy {

class Scalar : public torch::lazy::TorchMlirNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::prim::Constant);
  }

  Scalar(const at::Scalar& value, const at::ScalarType& type)
      : torch::lazy::TorchMlirNode(
              Scalar::ClassOpKind(),
              OpList{},
              compute_shape_scalar(value, type),
              /* num_outputs */ 1,
              torch::lazy::MHash(value, type)),
        value(value),
        type(type)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << torch::lazy::TorchMlirNode::ToString();
    ss << ", value=" << value;
    ss << ", type=" << type;
    return ss.str();
  }

  

  bool CanBeReused(const at::Scalar& value, const at::ScalarType& type) const {
    return false;
    }

  TorchMlirOpVector Lower(TorchMlirFunction function, TorchMlirLoweringContext* loctx) const override;

  at::Scalar value;
  at::ScalarType type;
  

};

class Expand : public torch::lazy::TorchMlirNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::expand);
  }

  Expand(const torch::lazy::Value& input, const ::std::vector<int64_t>& size, const bool& is_scalar_expand)
      : torch::lazy::TorchMlirNode(
              Expand::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_expand(operand(0), size, is_scalar_expand)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(size, is_scalar_expand)),
        size(size),
        is_scalar_expand(is_scalar_expand)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << torch::lazy::TorchMlirNode::ToString();
    ss << ", size=" << size;
    ss << ", is_scalar_expand=" << is_scalar_expand;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const ::std::vector<int64_t>& size, const bool& is_scalar_expand) const {
    return false;
    }

  TorchMlirOpVector Lower(TorchMlirFunction function, TorchMlirLoweringContext* loctx) const override;

  ::std::vector<int64_t> size;
  bool is_scalar_expand;
  

};

class Cast : public torch::lazy::TorchMlirNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(ltc_cast);
  }

  Cast(const torch::lazy::Value& input, const at::ScalarType& dtype, const c10::optional<at::ScalarType>& stype)
      : torch::lazy::TorchMlirNode(
              Cast::ClassOpKind(),
              OpList{input},
              compute_shape_cast(input, dtype, stype),
              /* num_outputs */ 1,
              torch::lazy::MHash(dtype, stype)),
        dtype(dtype),
        stype(stype)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << torch::lazy::TorchMlirNode::ToString();
    ss << ", dtype=" << dtype;
    if (stype.has_value()) {
      ss << ", stype=" << stype.value();
    } else {
      ss << ", stype=null";
    }
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const at::ScalarType& dtype, const c10::optional<at::ScalarType>& stype) const {
    return false;
    }

  TorchMlirOpVector Lower(TorchMlirFunction function, TorchMlirLoweringContext* loctx) const override;

  at::ScalarType dtype;
  c10::optional<at::ScalarType> stype;
  

};

} // namespace lazy
} // namespace torch
